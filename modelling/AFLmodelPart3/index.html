



<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Documentation, guides and articles on creating, developing and implementing automated betting strategies, using data analysis to inform betting models and how to interact with the Betfair API.">
      
      
        <link rel="canonical" href="https://betfair-datascientists.github.io/modelling/AFLmodelPart3/">
      
      
        <meta name="author" content="Betfair Data Scientists">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../../img/BetfairFavicon.ico">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-3.0.4">
    
    
      
        <title>AFL 03. Modelling - The Automation Hub</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/application.9a8eeed6.css">
      
      
    
    
      <script src="../../assets/javascripts/modernizr.1aa3b519.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../assets/fonts/material-icons.css">
    <link rel="stylesheet" href="../../assets/fonts/clarke-regular.css">
    
    
  </head>
  
    <body dir="ltr">
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="../../#afl-modelling-walkthrough" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://betfair-datascientists.github.io" title="The Automation Hub" class="md-header-nav__button md-logo">
          
            <img src="../../img/logo.svg" height="24">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                The Automation Hub
              </span>
              <span class="md-header-nav__topic">
                AFL 03. Modelling
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      <div class="bf-nav md-flex__cell">
        <a class="bf-hidable" href="https://www.betfair.com.au/exchange/plus/"><svg class="exchangeLogo" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:svg="http://www.w3.org/2000/svg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 38.775 4.59" width="24" height="17">
          <path class="st1" d="m 160.3,-136.95 v 26"/>
          <g transform="translate(18.8,-137.15)">
            <path d="m 2.2901089,126.53441 v 5.20093 H -3.3107216 L 7.4888397,144.33446 18.2884,131.73534 h -5.598633 v -5.20093 z m -8.6000974,8.10132 -10.8017585,12.59913 h 5.60083 v 5.2998 h 10.3996581 v -5.2998 h 5.6008306 z"/>
          </g>
        </svg><span> Exchange</span></a>
        <a href="https://www.betfair.com.au/hub/">Hub</a>
      </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../.." title="Home" class="md-tabs__link">
          Home
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../thirdPartyTools/betAngelRatingsAutomation/" title="Third Party Tools" class="md-tabs__link">
          Third Party Tools
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../api/apiappkey/" title="API" class="md-tabs__link">
          API
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../historicData/dataSources/" title="Historic Data" class="md-tabs__link">
          Historic Data
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../howToModel/" title="Modelling" class="md-tabs__link md-tabs__link--active">
          Modelling
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://betfair-datascientists.github.io" title="The Automation Hub" class="md-nav__button md-logo">
      
        <img src="../../img/logo.svg" width="48" height="48">
      
    </a>
    The Automation Hub
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-1" type="checkbox" id="nav-1">
    
    <label class="md-nav__link" for="nav-1">
      Home
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-1">
        Home
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../.." title="The Automation Hub" class="md-nav__link">
      The Automation Hub
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      Third Party Tools
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Third Party Tools
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../thirdPartyTools/betAngelRatingsAutomation/" title="Bet Angel - ratings automation" class="md-nav__link">
      Bet Angel - ratings automation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../thirdPartyTools/betAngelMarketFavouriteAutomation/" title="Bet Angel - market favourite automation" class="md-nav__link">
      Bet Angel - market favourite automation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../thirdPartyTools/betAngelTippingAutomation/" title="Bet Angel - tipping automation" class="md-nav__link">
      Bet Angel - tipping automation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../thirdPartyTools/grussRatingsAutomation/" title="Gruss - ratings automation" class="md-nav__link">
      Gruss - ratings automation
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      API
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        API
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../api/apiappkey/" title="How to access the Betfair API" class="md-nav__link">
      How to access the Betfair API
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../api/apiRtutorial/" title="API tutorials in R" class="md-nav__link">
      API tutorials in R
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../api/apiPythontutorial/" title="API tutorial in Python" class="md-nav__link">
      API tutorial in Python
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      Historic Data
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        Historic Data
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../historicData/dataSources/" title="Historic Data Sources" class="md-nav__link">
      Historic Data Sources
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../historicData/usingHistoricDataSite/" title="Downloading from the Historic Data site" class="md-nav__link">
      Downloading from the Historic Data site
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5" checked>
    
    <label class="md-nav__link" for="nav-5">
      Modelling
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Modelling
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../howToModel/" title="Intro to modelling" class="md-nav__link">
      Intro to modelling
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../EPLmodelPart1/" title="EPL 01. Data acquisition & exploration" class="md-nav__link">
      EPL 01. Data acquisition & exploration
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../EPLmodelPart2/" title="EPL 02. Data preparation & feature engineering" class="md-nav__link">
      EPL 02. Data preparation & feature engineering
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../EPLmodelPart3/" title="EPL 03. Model building & hyperparameter tuning" class="md-nav__link">
      EPL 03. Model building & hyperparameter tuning
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../EPLmodelPart4/" title="EPL 04. Weekly predictions" class="md-nav__link">
      EPL 04. Weekly predictions
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../AFLmodelPart1/" title="AFL 01. Data cleaning" class="md-nav__link">
      AFL 01. Data cleaning
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../AFLmodelPart2/" title="AFL 02. Feature creation" class="md-nav__link">
      AFL 02. Feature creation
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
    <a href="./" title="AFL 03. Modelling" class="md-nav__link md-nav__link--active">
      AFL 03. Modelling
    </a>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../AFLmodelPart4/" title="AFL 04. Weekly predictions" class="md-nav__link">
      AFL 04. Weekly predictions
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../brownlowModelTutorial/" title="Modelling the Brownlow Medal" class="md-nav__link">
      Modelling the Brownlow Medal
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="afl-modelling-walkthrough">AFL Modelling Walkthrough<a class="headerlink" href="#afl-modelling-walkthrough" title="Permanent link">&para;</a></h1>
<h1 id="03-modelling">03. Modelling<a class="headerlink" href="#03-modelling" title="Permanent link">&para;</a></h1>
<p>These tutorials will walk you through how to construct your own basic AFL model, using publically available data. The output will be odds for each team to win, which will be shown on <a href="https://www.betfair.com.au/hub/tools/models/afl-prediction-model/">The Hub</a>.</p>
<p>In this notebook we will walk you through modelling our AFL data to create predictions. We will train a variety of quick and easy models to get a feel of what works and what doesn't. We will then tune our hyperparameters so that we are ready to make week by week predictions.</p>
<hr />
<h2 id="grabbing-our-dataset">Grabbing Our Dataset<a class="headerlink" href="#grabbing-our-dataset" title="Permanent link">&para;</a></h2>
<p>First, we will import our required modules, as well as the prepare_afl_features function which we created in our afl_feature_creation script. This essentially creates some basic features for us so that we can get started on the modelling component.</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #408080; font-style: italic"># Import libraries</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">afl_data_cleaning_v2</span> <span style="color: #008000; font-weight: bold">import</span> <span style="color: #666666">*</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">datetime</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">pandas</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">pd</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn</span> <span style="color: #008000; font-weight: bold">import</span> svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process
<span style="color: #408080; font-style: italic"># from xgboost import XGBClassifier</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.model_selection</span> <span style="color: #008000; font-weight: bold">import</span> StratifiedKFold, cross_val_score, GridSearchCV, train_test_split
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.linear_model</span> <span style="color: #008000; font-weight: bold">import</span> LogisticRegressionCV
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.feature_selection</span> <span style="color: #008000; font-weight: bold">import</span> RFECV
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">seaborn</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">sns</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.preprocessing</span> <span style="color: #008000; font-weight: bold">import</span> OneHotEncoder, LabelEncoder, StandardScaler
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn</span> <span style="color: #008000; font-weight: bold">import</span> feature_selection
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn</span> <span style="color: #008000; font-weight: bold">import</span> metrics
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.linear_model</span> <span style="color: #008000; font-weight: bold">import</span> LogisticRegression, RidgeClassifier
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.ensemble</span> <span style="color: #008000; font-weight: bold">import</span> RandomForestClassifier
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.discriminant_analysis</span> <span style="color: #008000; font-weight: bold">import</span> LinearDiscriminantAnalysis
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.naive_bayes</span> <span style="color: #008000; font-weight: bold">import</span> GaussianNB
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">warnings</span>
warnings<span style="color: #666666">.</span>filterwarnings(<span style="color: #BA2121">&#39;ignore&#39;</span>)
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">afl_feature_creation_v2</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">afl_data_cleaning_v2</span>
</pre></div>

<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #408080; font-style: italic"># Grab our feature DataFrame which we created in the previous tutorial</span>
feature_df <span style="color: #666666">=</span> afl_feature_creation_v2<span style="color: #666666">.</span>prepare_afl_features()
afl_data <span style="color: #666666">=</span> afl_data_cleaning_v2<span style="color: #666666">.</span>prepare_afl_data()
</pre></div>

<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>feature_df<span style="color: #666666">.</span>tail(<span style="color: #666666">3</span>)
</pre></div>

<table>
<thead>
<tr>
<th></th>
<th>game</th>
<th>home_team</th>
<th>away_team</th>
<th>date</th>
<th>round</th>
<th>venue</th>
<th>season</th>
<th>f_odds</th>
<th>f_form_margin_btwn_teams</th>
<th>f_form_past_5_btwn_teams</th>
<th>f_odds_away</th>
<th>f_elo_home</th>
<th>f_elo_away</th>
<th>f_I50_efficiency_home</th>
<th>f_R50_efficiency_home</th>
<th>f_I50_efficiency_away</th>
<th>f_R50_efficiency_away</th>
<th>f_goals_diff</th>
<th>f_behinds_diff</th>
<th>f_points_diff</th>
<th>f_margin_diff</th>
<th>f_opponent_goals_diff</th>
<th>f_opponent_behinds_diff</th>
<th>f_opponent_points_diff</th>
<th>f_AF_diff</th>
<th>f_B_diff</th>
<th>f_BO_diff</th>
<th>f_CCL_diff</th>
<th>f_CG_diff</th>
<th>f_CL_diff</th>
<th>f_CM_diff</th>
<th>f_CP_diff</th>
<th>f_D_diff</th>
<th>f_ED_diff</th>
<th>f_FA_diff</th>
<th>f_FF_diff</th>
<th>f_G_diff</th>
<th>f_GA_diff</th>
<th>f_HB_diff</th>
<th>f_HO_diff</th>
<th>f_I50_diff</th>
<th>f_ITC_diff</th>
<th>f_K_diff</th>
<th>f_M_diff</th>
<th>f_MG_diff</th>
<th>f_MI5_diff</th>
<th>f_One.Percenters_diff</th>
<th>f_R50_diff</th>
<th>f_SC_diff</th>
<th>f_SCL_diff</th>
<th>f_SI_diff</th>
<th>f_T_diff</th>
<th>f_T5_diff</th>
<th>f_TO_diff</th>
<th>f_UP_diff</th>
<th>f_current_odds_prob</th>
<th>f_current_odds_prob_away</th>
</tr>
</thead>
<tbody>
<tr>
<td>1628</td>
<td>15396</td>
<td>Brisbane</td>
<td>West Coast</td>
<td>2018-08-26</td>
<td>23</td>
<td>Gabba</td>
<td>2018</td>
<td>3.442757</td>
<td>-49.2</td>
<td>0.0</td>
<td>2.094236</td>
<td>1279.963814</td>
<td>1622.200265</td>
<td>0.683604</td>
<td>0.691730</td>
<td>0.696822</td>
<td>0.709605</td>
<td>-0.190413</td>
<td>1.182699</td>
<td>0.040221</td>
<td>-13.621456</td>
<td>1.772577</td>
<td>3.026217</td>
<td>13.661677</td>
<td>-22.709485</td>
<td>2.424261</td>
<td>-4.848054</td>
<td>1.800473</td>
<td>5.051157</td>
<td>6.440524</td>
<td>-5.549630</td>
<td>-17.041838</td>
<td>27.543023</td>
<td>33.983159</td>
<td>4.459181</td>
<td>-3.213885</td>
<td>-0.428455</td>
<td>1.514474</td>
<td>42.646138</td>
<td>-7.141638</td>
<td>1.457375</td>
<td>-17.472537</td>
<td>-15.103115</td>
<td>8.001966</td>
<td>-383.083539</td>
<td>6.458915</td>
<td>7.275716</td>
<td>0.942863</td>
<td>44.461590</td>
<td>4.640136</td>
<td>13.180967</td>
<td>-15.704694</td>
<td>2.366444</td>
<td>-5.985843</td>
<td>38.195255</td>
<td>0.433501</td>
<td>0.569866</td>
</tr>
<tr>
<td>1629</td>
<td>15397</td>
<td>Melbourne</td>
<td>GWS</td>
<td>2018-08-26</td>
<td>23</td>
<td>M.C.G.</td>
<td>2018</td>
<td>1.706488</td>
<td>-23.2</td>
<td>2.0</td>
<td>1.805565</td>
<td>1540.367850</td>
<td>1615.614668</td>
<td>0.667240</td>
<td>0.692632</td>
<td>0.684525</td>
<td>0.753783</td>
<td>2.056899</td>
<td>0.635785</td>
<td>12.977177</td>
<td>6.642811</td>
<td>1.443121</td>
<td>-2.324358</td>
<td>6.334366</td>
<td>147.281112</td>
<td>2.201404</td>
<td>-5.222254</td>
<td>3.250416</td>
<td>8.542475</td>
<td>-2.203571</td>
<td>3.559792</td>
<td>21.192530</td>
<td>33.737734</td>
<td>12.865653</td>
<td>-3.244066</td>
<td>-2.135243</td>
<td>4.100203</td>
<td>3.772200</td>
<td>48.425291</td>
<td>18.247107</td>
<td>13.349992</td>
<td>11.385136</td>
<td>-14.687556</td>
<td>5.052000</td>
<td>304.087088</td>
<td>11.062610</td>
<td>-6.686409</td>
<td>-16.414544</td>
<td>8.350924</td>
<td>-5.453961</td>
<td>12.407662</td>
<td>6.672628</td>
<td>-1.523915</td>
<td>13.075351</td>
<td>18.522113</td>
<td>0.661551</td>
<td>0.340379</td>
</tr>
<tr>
<td>1630</td>
<td>15398</td>
<td>St Kilda</td>
<td>North Melbourne</td>
<td>2018-08-26</td>
<td>23</td>
<td>Docklands</td>
<td>2018</td>
<td>5.516150</td>
<td>-3.2</td>
<td>2.0</td>
<td>2.272313</td>
<td>1372.453734</td>
<td>1454.022032</td>
<td>0.730843</td>
<td>0.635819</td>
<td>0.697018</td>
<td>0.654991</td>
<td>-2.257517</td>
<td>1.223261</td>
<td>-12.321842</td>
<td>-19.923855</td>
<td>1.189755</td>
<td>0.463481</td>
<td>7.602012</td>
<td>27.891262</td>
<td>3.201137</td>
<td>4.754346</td>
<td>-1.881145</td>
<td>-3.924740</td>
<td>-0.528075</td>
<td>-8.045729</td>
<td>-20.584717</td>
<td>36.806235</td>
<td>39.615090</td>
<td>7.018240</td>
<td>-4.709732</td>
<td>-4.535660</td>
<td>-3.372912</td>
<td>23.194704</td>
<td>-18.042370</td>
<td>1.214353</td>
<td>-14.771187</td>
<td>13.611531</td>
<td>11.690647</td>
<td>-109.284521</td>
<td>-0.229945</td>
<td>12.384044</td>
<td>-4.625633</td>
<td>57.158576</td>
<td>1.353070</td>
<td>-1.533659</td>
<td>-6.646259</td>
<td>-3.489492</td>
<td>-15.416140</td>
<td>58.470456</td>
<td>0.284269</td>
<td>0.717566</td>
</tr>
</tbody>
</table>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #408080; font-style: italic"># Get the result and merge to the feature_df</span>

match_results <span style="color: #666666">=</span> (pd<span style="color: #666666">.</span>read_csv(<span style="color: #BA2121">&quot;data/afl_match_results.csv&quot;</span>)
                    <span style="color: #666666">.</span>rename(columns<span style="color: #666666">=</span>{<span style="color: #BA2121">&#39;Game&#39;</span>: <span style="color: #BA2121">&#39;game&#39;</span>})
                    <span style="color: #666666">.</span>assign(result<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">lambda</span> df: df<span style="color: #666666">.</span>apply(<span style="color: #008000; font-weight: bold">lambda</span> row: <span style="color: #666666">1</span> <span style="color: #008000; font-weight: bold">if</span> row[<span style="color: #BA2121">&#39;Home.Points&#39;</span>] <span style="color: #666666">&gt;</span> row[<span style="color: #BA2121">&#39;Away.Points&#39;</span>] <span style="color: #008000; font-weight: bold">else</span> <span style="color: #666666">0</span>, axis<span style="color: #666666">=1</span>)))

<span style="color: #408080; font-style: italic"># Merge result column to feature_df</span>
feature_df <span style="color: #666666">=</span> pd<span style="color: #666666">.</span>merge(feature_df, match_results[[<span style="color: #BA2121">&#39;game&#39;</span>, <span style="color: #BA2121">&#39;result&#39;</span>]], on<span style="color: #666666">=</span><span style="color: #BA2121">&#39;game&#39;</span>)
</pre></div>

<hr />
<h2 id="creating-a-training-and-testing-set">Creating a Training and Testing Set<a class="headerlink" href="#creating-a-training-and-testing-set" title="Permanent link">&para;</a></h2>
<p>So that we don't train our data on the data that we will later test our model on, we will create separate train and test sets. For this exercise we will use the 2018 season to test how our model performs, whilst the rest of the data can be used to train the model.</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #408080; font-style: italic"># Create our test and train sets from our afl DataFrame; drop the columns which leak the result, duplicates, and the advanced</span>
<span style="color: #408080; font-style: italic"># stats which don&#39;t have data until 2015</span>

feature_columns <span style="color: #666666">=</span> [col <span style="color: #008000; font-weight: bold">for</span> col <span style="color: #AA22FF; font-weight: bold">in</span> feature_df <span style="color: #008000; font-weight: bold">if</span> col<span style="color: #666666">.</span>startswith(<span style="color: #BA2121">&#39;f_&#39;</span>)]

<span style="color: #408080; font-style: italic"># Create our test set</span>
test_x <span style="color: #666666">=</span> feature_df<span style="color: #666666">.</span>loc[feature_df<span style="color: #666666">.</span>season <span style="color: #666666">==</span> <span style="color: #666666">2018</span>, [<span style="color: #BA2121">&#39;game&#39;</span>] <span style="color: #666666">+</span> feature_columns]
test_y <span style="color: #666666">=</span> feature_df<span style="color: #666666">.</span>loc[feature_df<span style="color: #666666">.</span>season <span style="color: #666666">==</span> <span style="color: #666666">2018</span>, <span style="color: #BA2121">&#39;result&#39;</span>]

<span style="color: #408080; font-style: italic"># Create our train set</span>
X <span style="color: #666666">=</span> feature_df<span style="color: #666666">.</span>loc[feature_df<span style="color: #666666">.</span>season <span style="color: #666666">!=</span> <span style="color: #666666">2018</span>, [<span style="color: #BA2121">&#39;game&#39;</span>] <span style="color: #666666">+</span> feature_columns]
y <span style="color: #666666">=</span> feature_df<span style="color: #666666">.</span>loc[feature_df<span style="color: #666666">.</span>season <span style="color: #666666">!=</span> <span style="color: #666666">2018</span>, <span style="color: #BA2121">&#39;result&#39;</span>]

<span style="color: #408080; font-style: italic"># Scale features</span>
scaler <span style="color: #666666">=</span> StandardScaler()
X[feature_columns] <span style="color: #666666">=</span> scaler<span style="color: #666666">.</span>fit_transform(X[feature_columns])
test_x[feature_columns] <span style="color: #666666">=</span> scaler<span style="color: #666666">.</span>transform(test_x[feature_columns])
</pre></div>

<hr />
<h2 id="using-cross-validation-to-find-the-best-algorithms">Using Cross Validation to Find The Best Algorithms<a class="headerlink" href="#using-cross-validation-to-find-the-best-algorithms" title="Permanent link">&para;</a></h2>
<p>Now that we have our training set, we can run through a list of popular classifiers to determine which classifier is best for modelling our data. To do this we will create a function which uses Kfold cross-validation to find the 'best' algorithms, based on how accurate the algorithms' predictions are.</p>
<p>This function will take in a list of classifiers, which we will define below, as well as the training set and it's outcome, and output a DataFrame with the mean and std of the accuracy of each algorithm. Let's jump into it!</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #408080; font-style: italic"># Create a list of standard classifiers</span>
classifiers <span style="color: #666666">=</span> [
    <span style="color: #408080; font-style: italic">#Ensemble Methods</span>
    ensemble<span style="color: #666666">.</span>AdaBoostClassifier(),
    ensemble<span style="color: #666666">.</span>BaggingClassifier(),
    ensemble<span style="color: #666666">.</span>ExtraTreesClassifier(),
    ensemble<span style="color: #666666">.</span>GradientBoostingClassifier(),
    ensemble<span style="color: #666666">.</span>RandomForestClassifier(),

    <span style="color: #408080; font-style: italic">#Gaussian Processes</span>
    gaussian_process<span style="color: #666666">.</span>GaussianProcessClassifier(),

    <span style="color: #408080; font-style: italic">#GLM</span>
    linear_model<span style="color: #666666">.</span>LogisticRegressionCV(),

    <span style="color: #408080; font-style: italic">#Navies Bayes</span>
    naive_bayes<span style="color: #666666">.</span>BernoulliNB(),
    naive_bayes<span style="color: #666666">.</span>GaussianNB(),

    <span style="color: #408080; font-style: italic">#SVM</span>
    svm<span style="color: #666666">.</span>SVC(probability<span style="color: #666666">=</span><span style="color: #008000">True</span>),
    svm<span style="color: #666666">.</span>NuSVC(probability<span style="color: #666666">=</span><span style="color: #008000">True</span>),

    <span style="color: #408080; font-style: italic">#Discriminant Analysis</span>
    discriminant_analysis<span style="color: #666666">.</span>LinearDiscriminantAnalysis(),
    discriminant_analysis<span style="color: #666666">.</span>QuadraticDiscriminantAnalysis(),

    <span style="color: #408080; font-style: italic">#xgboost: http://xgboost.readthedocs.io/en/latest/model.html</span>
<span style="color: #408080; font-style: italic">#     XGBClassifier()    </span>
]

<span style="color: #408080; font-style: italic"># Define a functiom which finds the best algorithms for our modelling task</span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">find_best_algorithms</span>(classifier_list, X, y):
    <span style="color: #408080; font-style: italic"># This function is adapted from https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling</span>
    <span style="color: #408080; font-style: italic"># Cross validate model with Kfold stratified cross validation</span>
    kfold <span style="color: #666666">=</span> StratifiedKFold(n_splits<span style="color: #666666">=5</span>)

    <span style="color: #408080; font-style: italic"># Grab the cross validation scores for each algorithm</span>
    cv_results <span style="color: #666666">=</span> [cross_val_score(classifier, X, y, scoring <span style="color: #666666">=</span> <span style="color: #BA2121">&quot;neg_log_loss&quot;</span>, cv <span style="color: #666666">=</span> kfold) <span style="color: #008000; font-weight: bold">for</span> classifier <span style="color: #AA22FF; font-weight: bold">in</span> classifier_list]
    cv_means <span style="color: #666666">=</span> [cv_result<span style="color: #666666">.</span>mean() <span style="color: #666666">*</span> <span style="color: #666666">-1</span> <span style="color: #008000; font-weight: bold">for</span> cv_result <span style="color: #AA22FF; font-weight: bold">in</span> cv_results]
    cv_std <span style="color: #666666">=</span> [cv_result<span style="color: #666666">.</span>std() <span style="color: #008000; font-weight: bold">for</span> cv_result <span style="color: #AA22FF; font-weight: bold">in</span> cv_results]
    algorithm_names <span style="color: #666666">=</span> [alg<span style="color: #666666">.</span><span style="color: #19177C">__class__</span><span style="color: #666666">.</span><span style="color: #19177C">__name__</span> <span style="color: #008000; font-weight: bold">for</span> alg <span style="color: #AA22FF; font-weight: bold">in</span> classifiers]

    <span style="color: #408080; font-style: italic"># Create a DataFrame of all the CV results</span>
    cv_results <span style="color: #666666">=</span> pd<span style="color: #666666">.</span>DataFrame({
        <span style="color: #BA2121">&quot;Mean Log Loss&quot;</span>: cv_means,
        <span style="color: #BA2121">&quot;Log Loss Std&quot;</span>: cv_std,
        <span style="color: #BA2121">&quot;Algorithm&quot;</span>: algorithm_names
    })

    <span style="color: #008000; font-weight: bold">return</span> cv_results<span style="color: #666666">.</span>sort_values(by<span style="color: #666666">=</span><span style="color: #BA2121">&#39;Mean Log Loss&#39;</span>)<span style="color: #666666">.</span>reset_index(drop<span style="color: #666666">=</span><span style="color: #008000">True</span>)
</pre></div>

<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>best_algos <span style="color: #666666">=</span> find_best_algorithms(classifiers, X, y)
best_algos
</pre></div>

<table>
<thead>
<tr>
<th></th>
<th>Mean Log Loss</th>
<th>Log Loss Std</th>
<th>Algorithm</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0.539131</td>
<td>3.640578e-02</td>
<td>LogisticRegressionCV</td>
</tr>
<tr>
<td>1</td>
<td>0.551241</td>
<td>5.775685e-02</td>
<td>LinearDiscriminantAnalysis</td>
</tr>
<tr>
<td>2</td>
<td>0.630994</td>
<td>8.257481e-02</td>
<td>GradientBoostingClassifier</td>
</tr>
<tr>
<td>3</td>
<td>0.670041</td>
<td>9.205780e-03</td>
<td>AdaBoostClassifier</td>
</tr>
<tr>
<td>4</td>
<td>0.693147</td>
<td>2.360121e-08</td>
<td>GaussianProcessClassifier</td>
</tr>
<tr>
<td>5</td>
<td>0.712537</td>
<td>2.770864e-02</td>
<td>SVC</td>
</tr>
<tr>
<td>6</td>
<td>0.712896</td>
<td>2.440755e-02</td>
<td>NuSVC</td>
</tr>
<tr>
<td>7</td>
<td>0.836191</td>
<td>2.094224e-01</td>
<td>ExtraTreesClassifier</td>
</tr>
<tr>
<td>8</td>
<td>0.874307</td>
<td>1.558144e-01</td>
<td>RandomForestClassifier</td>
</tr>
<tr>
<td>9</td>
<td>1.288174</td>
<td>3.953037e-01</td>
<td>BaggingClassifier</td>
</tr>
<tr>
<td>10</td>
<td>1.884019</td>
<td>4.769589e-01</td>
<td>QuadraticDiscriminantAnalysis</td>
</tr>
<tr>
<td>11</td>
<td>2.652161</td>
<td>6.886897e-01</td>
<td>BernoulliNB</td>
</tr>
<tr>
<td>12</td>
<td>3.299651</td>
<td>6.427551e-01</td>
<td>GaussianNB</td>
</tr>
</tbody>
</table>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #408080; font-style: italic"># Try a logistic regression model and see how it performs in terms of accuracy</span>
kfold <span style="color: #666666">=</span> StratifiedKFold(n_splits<span style="color: #666666">=5</span>)
cv_scores <span style="color: #666666">=</span> cross_val_score(linear_model<span style="color: #666666">.</span>LogisticRegressionCV(), X, y, scoring<span style="color: #666666">=</span><span style="color: #BA2121">&#39;accuracy&#39;</span>, cv<span style="color: #666666">=</span>kfold)
cv_scores<span style="color: #666666">.</span>mean()
    <span style="color: #666666">0.7452268937025035</span>
</pre></div>

<h3 id="choosing-our-algorithms">Choosing Our Algorithms<a class="headerlink" href="#choosing-our-algorithms" title="Permanent link">&para;</a></h3>
<p>As we can see from above, there are some pretty poor algorithms for predicting the winner. On the other hand, whilst attaining an accuracy of 74.5% (at the time of writing) may seem like a decent result; we must first establish a baseline to judge our performance on. In this case, we will have two baselines; the proportion of games won by the home team and what the odds predict. If we can beat the odds we have created a very powerful model.</p>
<p>Note that a baseline for the log loss can also be both the odds log loss and randomly guessing. Randomly guessing between two teams attains a log loss of log(2) = 0.69, so we have beaten this result.</p>
<p>Once we establish our baseline, we will choose the top algorithms from above and tune their hyperparameters, as well as automatically selecting the best features to be used in our model.</p>
<hr />
<h2 id="defining-our-baseline">Defining Our Baseline<a class="headerlink" href="#defining-our-baseline" title="Permanent link">&para;</a></h2>
<p>As stated above, we must define our baseline so that we have a measure to beat. We will use the proportion of games won by the home team, as well as the proportion of favourites who won, based off the odds. To establish this baseline we will use our feature_df, as this has no dropped rows.</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #408080; font-style: italic"># Find the percentage chance of winning at home in each season.</span>
afl_data <span style="color: #666666">=</span> afl_data_cleaning_v2<span style="color: #666666">.</span>prepare_afl_data()
afl_data[<span style="color: #BA2121">&#39;home_win&#39;</span>] <span style="color: #666666">=</span> afl_data<span style="color: #666666">.</span>apply(<span style="color: #008000; font-weight: bold">lambda</span> x: <span style="color: #666666">1</span> <span style="color: #008000; font-weight: bold">if</span> x[<span style="color: #BA2121">&#39;f_margin&#39;</span>] <span style="color: #666666">&gt;</span> <span style="color: #666666">0</span> <span style="color: #008000; font-weight: bold">else</span> <span style="color: #666666">0</span>, axis<span style="color: #666666">=1</span>)
home_games <span style="color: #666666">=</span> afl_data[afl_data[<span style="color: #BA2121">&#39;home_game&#39;</span>] <span style="color: #666666">==</span> <span style="color: #666666">1</span>]
home_games[[<span style="color: #BA2121">&quot;home_win&quot;</span>, <span style="color: #BA2121">&#39;season&#39;</span>]]<span style="color: #666666">.</span>groupby([<span style="color: #BA2121">&#39;season&#39;</span>])<span style="color: #666666">.</span>mean()
</pre></div>

<table>
<thead>
<tr>
<th>season</th>
<th>home_win</th>
</tr>
</thead>
<tbody>
<tr>
<td>2011</td>
<td>0.561856</td>
</tr>
<tr>
<td>2012</td>
<td>0.563725</td>
</tr>
<tr>
<td>2013</td>
<td>0.561576</td>
</tr>
<tr>
<td>2014</td>
<td>0.574257</td>
</tr>
<tr>
<td>2015</td>
<td>0.539604</td>
</tr>
<tr>
<td>2016</td>
<td>0.606742</td>
</tr>
<tr>
<td>2017</td>
<td>0.604061</td>
</tr>
<tr>
<td>2018</td>
<td>0.540404</td>
</tr>
</tbody>
</table>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #408080; font-style: italic"># Find the proportion of favourites who have won</span>

<span style="color: #408080; font-style: italic"># Define a function which finds if the odds correctly guessed the response</span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">find_odds_prediction</span>(a_row):
    <span style="color: #008000; font-weight: bold">if</span> a_row[<span style="color: #BA2121">&#39;f_odds&#39;</span>] <span style="color: #666666">&lt;=</span> a_row[<span style="color: #BA2121">&#39;f_odds_away&#39;</span>] <span style="color: #AA22FF; font-weight: bold">and</span> a_row[<span style="color: #BA2121">&#39;home_win&#39;</span>] <span style="color: #666666">==</span> <span style="color: #666666">1</span>:
        <span style="color: #008000; font-weight: bold">return</span> <span style="color: #666666">1</span>
    <span style="color: #008000; font-weight: bold">elif</span> a_row[<span style="color: #BA2121">&#39;f_odds_away&#39;</span>] <span style="color: #666666">&lt;</span> a_row[<span style="color: #BA2121">&#39;f_odds&#39;</span>] <span style="color: #AA22FF; font-weight: bold">and</span> a_row[<span style="color: #BA2121">&#39;home_win&#39;</span>] <span style="color: #666666">==</span> <span style="color: #666666">0</span>:
        <span style="color: #008000; font-weight: bold">return</span> <span style="color: #666666">1</span>
    <span style="color: #008000; font-weight: bold">else</span>:
        <span style="color: #008000; font-weight: bold">return</span> <span style="color: #666666">0</span>

<span style="color: #408080; font-style: italic"># Define a function which splits our DataFrame so each game is on one row instead of two</span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">get_df_on_one_line</span>(df):
    cols_to_drop <span style="color: #666666">=</span> [<span style="color: #BA2121">&#39;date&#39;</span>, <span style="color: #BA2121">&#39;home_game&#39;</span>, <span style="color: #BA2121">&#39;opponent&#39;</span>, 
       <span style="color: #BA2121">&#39;f_opponent_behinds&#39;</span>, <span style="color: #BA2121">&#39;f_opponent_goals&#39;</span>, <span style="color: #BA2121">&#39;f_opponent_points&#39;</span>, <span style="color: #BA2121">&#39;f_points&#39;</span>,
       <span style="color: #BA2121">&#39;round&#39;</span>, <span style="color: #BA2121">&#39;venue&#39;</span>, <span style="color: #BA2121">&#39;season&#39;</span>]

    home_df <span style="color: #666666">=</span> df[df[<span style="color: #BA2121">&#39;home_game&#39;</span>] <span style="color: #666666">==</span> <span style="color: #666666">1</span>]<span style="color: #666666">.</span>rename(columns<span style="color: #666666">=</span>{<span style="color: #BA2121">&#39;team&#39;</span>: <span style="color: #BA2121">&#39;home_team&#39;</span>})
    away_df <span style="color: #666666">=</span> df[df[<span style="color: #BA2121">&#39;home_game&#39;</span>] <span style="color: #666666">==</span> <span style="color: #666666">0</span>]<span style="color: #666666">.</span>rename(columns<span style="color: #666666">=</span>{<span style="color: #BA2121">&#39;team&#39;</span>: <span style="color: #BA2121">&#39;away_team&#39;</span>})
    away_df <span style="color: #666666">=</span> away_df<span style="color: #666666">.</span>drop(columns<span style="color: #666666">=</span>cols_to_drop)

    <span style="color: #408080; font-style: italic"># Rename away_df columns</span>
    away_df_renamed <span style="color: #666666">=</span> away_df<span style="color: #666666">.</span>rename(columns<span style="color: #666666">=</span>{col: col <span style="color: #666666">+</span> <span style="color: #BA2121">&#39;_away&#39;</span> <span style="color: #008000; font-weight: bold">for</span> col <span style="color: #AA22FF; font-weight: bold">in</span> away_df<span style="color: #666666">.</span>columns <span style="color: #008000; font-weight: bold">if</span> col <span style="color: #666666">!=</span> <span style="color: #BA2121">&#39;game&#39;</span>})
    merged_df <span style="color: #666666">=</span> pd<span style="color: #666666">.</span>merge(home_df, away_df_renamed, on<span style="color: #666666">=</span><span style="color: #BA2121">&#39;game&#39;</span>)

    merged_df[<span style="color: #BA2121">&#39;home_win&#39;</span>] <span style="color: #666666">=</span> merged_df<span style="color: #666666">.</span>f_margin<span style="color: #666666">.</span>apply(<span style="color: #008000; font-weight: bold">lambda</span> x: <span style="color: #666666">1</span> <span style="color: #008000; font-weight: bold">if</span> x <span style="color: #666666">&gt;</span> <span style="color: #666666">0</span> <span style="color: #008000; font-weight: bold">else</span> <span style="color: #666666">0</span>)
    <span style="color: #008000; font-weight: bold">return</span> merged_df

afl_data_one_line <span style="color: #666666">=</span> get_df_on_one_line(afl_data)
afl_data_one_line[<span style="color: #BA2121">&#39;odds_prediction&#39;</span>] <span style="color: #666666">=</span> afl_data_one_line<span style="color: #666666">.</span>apply(find_odds_prediction, axis<span style="color: #666666">=1</span>)
<span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&#39;The overall mean accuracy of choosing the favourite based on the odds is {}%&#39;</span><span style="color: #666666">.</span>format(
    <span style="color: #008000">round</span>(afl_data_one_line[<span style="color: #BA2121">&#39;odds_prediction&#39;</span>]<span style="color: #666666">.</span>mean() <span style="color: #666666">*</span> <span style="color: #666666">100</span>, <span style="color: #666666">2</span>)))
afl_data_one_line[[<span style="color: #BA2121">&quot;odds_prediction&quot;</span>, <span style="color: #BA2121">&#39;season&#39;</span>]]<span style="color: #666666">.</span>groupby([<span style="color: #BA2121">&#39;season&#39;</span>])<span style="color: #666666">.</span>mean()
</pre></div>

<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>The overall mean accuracy of choosing the favourite based on the odds is 73.15%
</pre></div>


<table>
<thead>
<tr>
<th>season</th>
<th>odds_prediction</th>
</tr>
</thead>
<tbody>
<tr>
<td>2011</td>
<td>0.784615</td>
</tr>
<tr>
<td>2012</td>
<td>0.774510</td>
</tr>
<tr>
<td>2013</td>
<td>0.748768</td>
</tr>
<tr>
<td>2014</td>
<td>0.727723</td>
</tr>
<tr>
<td>2015</td>
<td>0.727723</td>
</tr>
<tr>
<td>2016</td>
<td>0.713483</td>
</tr>
<tr>
<td>2017</td>
<td>0.659898</td>
</tr>
<tr>
<td>2018</td>
<td>0.712121</td>
</tr>
</tbody>
</table>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #408080; font-style: italic">## Get a baseline log loss score from the odds</span>
afl_data_one_line[<span style="color: #BA2121">&#39;odds_home_prob&#39;</span>] <span style="color: #666666">=</span> <span style="color: #666666">1</span> <span style="color: #666666">/</span> afl_data_one_line<span style="color: #666666">.</span>f_odds
afl_data_one_line[<span style="color: #BA2121">&#39;odds_away_prob&#39;</span>] <span style="color: #666666">=</span> <span style="color: #666666">1</span> <span style="color: #666666">/</span> afl_data_one_line<span style="color: #666666">.</span>f_odds_away
</pre></div>

<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>metrics<span style="color: #666666">.</span>log_loss(afl_data_one_line<span style="color: #666666">.</span>home_win, afl_data_one_line[[<span style="color: #BA2121">&#39;odds_away_prob&#39;</span>, <span style="color: #BA2121">&#39;odds_home_prob&#39;</span>]])
    <span style="color: #666666">0.5375306549682837</span>
</pre></div>

<p>We can see that the odds are MUCH more accurate than just choosing the home team to win. We can also see that the mean accuracy of choosing the favourite is around 73%. That means that this is the score we need to beat. Similarly, the log loss of the odds is around 0.5385, whilst our model scores around 0.539 (at the time of writing), without hyperparamter optimisation. Let's choose only the algorithms with log losses below 0.67</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>chosen_algorithms <span style="color: #666666">=</span> best_algos<span style="color: #666666">.</span>loc[best_algos[<span style="color: #BA2121">&#39;Mean Log Loss&#39;</span>] <span style="color: #666666">&lt;</span> <span style="color: #666666">0.67</span>, <span style="color: #BA2121">&#39;Algorithm&#39;</span>]<span style="color: #666666">.</span>tolist()
chosen_algorithms
    [<span style="color: #BA2121">&#39;LogisticRegressionCV&#39;</span>,
     <span style="color: #BA2121">&#39;LinearDiscriminantAnalysis&#39;</span>,
     <span style="color: #BA2121">&#39;GradientBoostingClassifier&#39;</span>]
</pre></div>

<hr />
<h2 id="using-grid-search-to-tune-hyperparameters">Using Grid Search To Tune Hyperparameters<a class="headerlink" href="#using-grid-search-to-tune-hyperparameters" title="Permanent link">&para;</a></h2>
<p>Now that we have our best models, we can use <a href="https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search">Grid Search</a> to optimise our hyperparameters. Grid search basically involves searching through a range of different algorithm hyperparameters, and choosing those which result in the best score from some metrics, which in our case is accuracy. Let's do this for the algorithms which have hyperparameters which can be tuned. Note that if you are running this on your own computer it may take up to 10 minutes.</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #408080; font-style: italic"># Define a function which optimises the hyperparameters of our chosen algorithms</span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">optimise_hyperparameters</span>(train_x, train_y, algorithms, parameters):
    kfold <span style="color: #666666">=</span> StratifiedKFold(n_splits<span style="color: #666666">=5</span>)
    best_estimators <span style="color: #666666">=</span> []

    <span style="color: #008000; font-weight: bold">for</span> alg, params <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">zip</span>(algorithms, parameters):
        gs <span style="color: #666666">=</span> GridSearchCV(alg, param_grid<span style="color: #666666">=</span>params, cv<span style="color: #666666">=</span>kfold, scoring<span style="color: #666666">=</span><span style="color: #BA2121">&#39;neg_log_loss&#39;</span>, verbose<span style="color: #666666">=1</span>)
        gs<span style="color: #666666">.</span>fit(train_x, train_y)
        best_estimators<span style="color: #666666">.</span>append(gs<span style="color: #666666">.</span>best_estimator_)
    <span style="color: #008000; font-weight: bold">return</span> best_estimators

<span style="color: #408080; font-style: italic"># Define our parameters to run a grid search over</span>
lr_grid <span style="color: #666666">=</span> {
    <span style="color: #BA2121">&quot;C&quot;</span>: [<span style="color: #666666">0.0001</span>, <span style="color: #666666">0.001</span>, <span style="color: #666666">0.01</span>, <span style="color: #666666">0.05</span>, <span style="color: #666666">0.2</span>, <span style="color: #666666">0.5</span>],
    <span style="color: #BA2121">&quot;solver&quot;</span>: [<span style="color: #BA2121">&quot;newton-cg&quot;</span>, <span style="color: #BA2121">&quot;lbfgs&quot;</span>, <span style="color: #BA2121">&quot;liblinear&quot;</span>]
}

<span style="color: #408080; font-style: italic"># Add our algorithms and parameters to lists to be used in our function</span>
alg_list <span style="color: #666666">=</span> [LogisticRegression()]
param_list <span style="color: #666666">=</span> [lr_grid]
</pre></div>

<p><div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #408080; font-style: italic"># Find the best estimators, then add our other estimators which don&#39;t need optimisation</span>
best_estimators <span style="color: #666666">=</span> optimise_hyperparameters(X, y, alg_list, param_list)
</pre></div>
    Fitting 5 folds for each of 18 candidates, totalling 90 fits</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:    5.2s finished
</pre></div>


<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>lr_best_params <span style="color: #666666">=</span> best_estimators[<span style="color: #666666">0</span>]<span style="color: #666666">.</span>get_params()
lr_best_params
    {<span style="color: #BA2121">&#39;C&#39;</span>: <span style="color: #666666">0.01</span>,
     <span style="color: #BA2121">&#39;class_weight&#39;</span>: <span style="color: #008000">None</span>,
     <span style="color: #BA2121">&#39;dual&#39;</span>: <span style="color: #008000">False</span>,
     <span style="color: #BA2121">&#39;fit_intercept&#39;</span>: <span style="color: #008000">True</span>,
     <span style="color: #BA2121">&#39;intercept_scaling&#39;</span>: <span style="color: #666666">1</span>,
     <span style="color: #BA2121">&#39;max_iter&#39;</span>: <span style="color: #666666">100</span>,
     <span style="color: #BA2121">&#39;multi_class&#39;</span>: <span style="color: #BA2121">&#39;ovr&#39;</span>,
     <span style="color: #BA2121">&#39;n_jobs&#39;</span>: <span style="color: #666666">1</span>,
     <span style="color: #BA2121">&#39;penalty&#39;</span>: <span style="color: #BA2121">&#39;l2&#39;</span>,
     <span style="color: #BA2121">&#39;random_state&#39;</span>: <span style="color: #008000">None</span>,
     <span style="color: #BA2121">&#39;solver&#39;</span>: <span style="color: #BA2121">&#39;newton-cg&#39;</span>,
     <span style="color: #BA2121">&#39;tol&#39;</span>: <span style="color: #666666">0.0001</span>,
     <span style="color: #BA2121">&#39;verbose&#39;</span>: <span style="color: #666666">0</span>,
     <span style="color: #BA2121">&#39;warm_start&#39;</span>: <span style="color: #008000">False</span>}
</pre></div>

<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>kfold <span style="color: #666666">=</span> StratifiedKFold(n_splits<span style="color: #666666">=10</span>)
cv_scores <span style="color: #666666">=</span> cross_val_score(linear_model<span style="color: #666666">.</span>LogisticRegression(<span style="color: #666666">**</span>lr_best_params), X, y, scoring<span style="color: #666666">=</span><span style="color: #BA2121">&#39;neg_log_loss&#39;</span>, cv<span style="color: #666666">=</span>kfold)
cv_scores<span style="color: #666666">.</span>mean()
    <span style="color: #666666">-0.528741673153639</span>
</pre></div>

<p>In the next iteration of this tutorial we will also optimise an XGB model and hopefully outperform our logistic regression model.</p>
<hr />
<h2 id="creating-predictions-for-the-2018-season">Creating Predictions for the 2018 Season<a class="headerlink" href="#creating-predictions-for-the-2018-season" title="Permanent link">&para;</a></h2>
<p>Now that we have an optimised logistic regression model, let's see how it performs on predicting the 2018 season.</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>lr <span style="color: #666666">=</span> LogisticRegression(<span style="color: #666666">**</span>lr_best_params)
lr<span style="color: #666666">.</span>fit(X, y)
final_predictions <span style="color: #666666">=</span> lr<span style="color: #666666">.</span>predict(test_x)

accuracy <span style="color: #666666">=</span> (final_predictions <span style="color: #666666">==</span> test_y)<span style="color: #666666">.</span>mean() <span style="color: #666666">*</span> <span style="color: #666666">100</span>

<span style="color: #008000; font-weight: bold">print</span>(<span style="color: #BA2121">&quot;Our accuracy in predicting the 2018 season is: {:.2f}%&quot;</span><span style="color: #666666">.</span>format(accuracy))
</pre></div>

<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>Our accuracy in predicting the 2018 season is: 67.68%
</pre></div>


<p>Now let's have a look at all the games which we incorrectly predicted.</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>game_ids <span style="color: #666666">=</span> test_x[(final_predictions <span style="color: #666666">!=</span> test_y)]<span style="color: #666666">.</span>game
afl_data_one_line<span style="color: #666666">.</span>loc[afl_data_one_line<span style="color: #666666">.</span>game<span style="color: #666666">.</span>isin(game_ids), [<span style="color: #BA2121">&#39;date&#39;</span>, <span style="color: #BA2121">&#39;home_team&#39;</span>, <span style="color: #BA2121">&#39;opponent&#39;</span>, <span style="color: #BA2121">&#39;f_odds&#39;</span>, <span style="color: #BA2121">&#39;f_odds_away&#39;</span>, <span style="color: #BA2121">&#39;f_margin&#39;</span>]]
</pre></div>

<table>
<thead>
<tr>
<th></th>
<th>date</th>
<th>home_team</th>
<th>opponent</th>
<th>f_odds</th>
<th>f_odds_away</th>
<th>f_margin</th>
</tr>
</thead>
<tbody>
<tr>
<td>1386</td>
<td>2018-03-24</td>
<td>Gold Coast</td>
<td>North Melbourne</td>
<td>2.0161</td>
<td>1.9784</td>
<td>16</td>
</tr>
<tr>
<td>1388</td>
<td>2018-03-25</td>
<td>Melbourne</td>
<td>Geelong</td>
<td>1.7737</td>
<td>2.2755</td>
<td>-3</td>
</tr>
<tr>
<td>1391</td>
<td>2018-03-30</td>
<td>North Melbourne</td>
<td>St Kilda</td>
<td>3.5769</td>
<td>1.3867</td>
<td>52</td>
</tr>
<tr>
<td>1392</td>
<td>2018-03-31</td>
<td>Carlton</td>
<td>Gold Coast</td>
<td>1.5992</td>
<td>2.6620</td>
<td>-34</td>
</tr>
<tr>
<td>1396</td>
<td>2018-04-01</td>
<td>Western Bulldogs</td>
<td>West Coast</td>
<td>1.8044</td>
<td>2.2445</td>
<td>-51</td>
</tr>
<tr>
<td>1397</td>
<td>2018-04-01</td>
<td>Sydney</td>
<td>Port Adelaide</td>
<td>1.4949</td>
<td>3.0060</td>
<td>-23</td>
</tr>
<tr>
<td>1398</td>
<td>2018-04-02</td>
<td>Geelong</td>
<td>Hawthorn</td>
<td>1.7597</td>
<td>2.3024</td>
<td>-1</td>
</tr>
<tr>
<td>1406</td>
<td>2018-04-08</td>
<td>Western Bulldogs</td>
<td>Essendon</td>
<td>3.8560</td>
<td>1.3538</td>
<td>21</td>
</tr>
<tr>
<td>1408</td>
<td>2018-04-13</td>
<td>Adelaide</td>
<td>Collingwood</td>
<td>1.2048</td>
<td>5.9197</td>
<td>-48</td>
</tr>
<tr>
<td>1412</td>
<td>2018-04-14</td>
<td>North Melbourne</td>
<td>Carlton</td>
<td>1.5799</td>
<td>2.7228</td>
<td>86</td>
</tr>
<tr>
<td>1415</td>
<td>2018-04-15</td>
<td>Hawthorn</td>
<td>Melbourne</td>
<td>2.2855</td>
<td>1.7772</td>
<td>67</td>
</tr>
<tr>
<td>1417</td>
<td>2018-04-20</td>
<td>Sydney</td>
<td>Adelaide</td>
<td>1.2640</td>
<td>4.6929</td>
<td>-10</td>
</tr>
<tr>
<td>1420</td>
<td>2018-04-21</td>
<td>Port Adelaide</td>
<td>Geelong</td>
<td>1.5053</td>
<td>2.9515</td>
<td>-34</td>
</tr>
<tr>
<td>1422</td>
<td>2018-04-22</td>
<td>North Melbourne</td>
<td>Hawthorn</td>
<td>2.6170</td>
<td>1.6132</td>
<td>28</td>
</tr>
<tr>
<td>1423</td>
<td>2018-04-22</td>
<td>Brisbane</td>
<td>Gold Coast</td>
<td>1.7464</td>
<td>2.3277</td>
<td>-5</td>
</tr>
<tr>
<td>1425</td>
<td>2018-04-25</td>
<td>Collingwood</td>
<td>Essendon</td>
<td>1.8372</td>
<td>2.1754</td>
<td>49</td>
</tr>
<tr>
<td>1427</td>
<td>2018-04-28</td>
<td>Geelong</td>
<td>Sydney</td>
<td>1.5019</td>
<td>2.9833</td>
<td>-17</td>
</tr>
<tr>
<td>1434</td>
<td>2018-04-29</td>
<td>Fremantle</td>
<td>West Coast</td>
<td>2.4926</td>
<td>1.6531</td>
<td>-8</td>
</tr>
<tr>
<td>1437</td>
<td>2018-05-05</td>
<td>Essendon</td>
<td>Hawthorn</td>
<td>2.8430</td>
<td>1.5393</td>
<td>-23</td>
</tr>
<tr>
<td>1439</td>
<td>2018-05-05</td>
<td>Sydney</td>
<td>North Melbourne</td>
<td>1.2777</td>
<td>4.5690</td>
<td>-2</td>
</tr>
<tr>
<td>1444</td>
<td>2018-05-11</td>
<td>Hawthorn</td>
<td>Sydney</td>
<td>1.6283</td>
<td>2.5818</td>
<td>-8</td>
</tr>
<tr>
<td>1445</td>
<td>2018-05-12</td>
<td>GWS</td>
<td>West Coast</td>
<td>1.5425</td>
<td>2.8292</td>
<td>-25</td>
</tr>
<tr>
<td>1446</td>
<td>2018-05-12</td>
<td>Carlton</td>
<td>Essendon</td>
<td>3.1742</td>
<td>1.4570</td>
<td>13</td>
</tr>
<tr>
<td>1452</td>
<td>2018-05-13</td>
<td>Collingwood</td>
<td>Geelong</td>
<td>2.4127</td>
<td>1.7040</td>
<td>-21</td>
</tr>
<tr>
<td>1455</td>
<td>2018-05-19</td>
<td>North Melbourne</td>
<td>GWS</td>
<td>1.5049</td>
<td>2.9752</td>
<td>43</td>
</tr>
<tr>
<td>1456</td>
<td>2018-05-19</td>
<td>Essendon</td>
<td>Geelong</td>
<td>5.6530</td>
<td>1.2104</td>
<td>34</td>
</tr>
<tr>
<td>1460</td>
<td>2018-05-20</td>
<td>Brisbane</td>
<td>Hawthorn</td>
<td>3.2891</td>
<td>1.4318</td>
<td>56</td>
</tr>
<tr>
<td>1461</td>
<td>2018-05-20</td>
<td>West Coast</td>
<td>Richmond</td>
<td>1.9755</td>
<td>2.0154</td>
<td>47</td>
</tr>
<tr>
<td>1466</td>
<td>2018-05-26</td>
<td>GWS</td>
<td>Essendon</td>
<td>1.4364</td>
<td>3.2652</td>
<td>-35</td>
</tr>
<tr>
<td>1467</td>
<td>2018-05-27</td>
<td>Hawthorn</td>
<td>West Coast</td>
<td>2.2123</td>
<td>1.8133</td>
<td>-15</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>1483</td>
<td>2018-06-10</td>
<td>Brisbane</td>
<td>Essendon</td>
<td>2.3018</td>
<td>1.7543</td>
<td>-22</td>
</tr>
<tr>
<td>1485</td>
<td>2018-06-11</td>
<td>Melbourne</td>
<td>Collingwood</td>
<td>1.6034</td>
<td>2.6450</td>
<td>-42</td>
</tr>
<tr>
<td>1492</td>
<td>2018-06-21</td>
<td>West Coast</td>
<td>Essendon</td>
<td>1.3694</td>
<td>3.6843</td>
<td>-28</td>
</tr>
<tr>
<td>1493</td>
<td>2018-06-22</td>
<td>Port Adelaide</td>
<td>Melbourne</td>
<td>1.7391</td>
<td>2.3426</td>
<td>10</td>
</tr>
<tr>
<td>1499</td>
<td>2018-06-29</td>
<td>Western Bulldogs</td>
<td>Geelong</td>
<td>6.2067</td>
<td>1.1889</td>
<td>2</td>
</tr>
<tr>
<td>1501</td>
<td>2018-06-30</td>
<td>Adelaide</td>
<td>West Coast</td>
<td>1.4989</td>
<td>2.9756</td>
<td>10</td>
</tr>
<tr>
<td>1504</td>
<td>2018-07-01</td>
<td>Melbourne</td>
<td>St Kilda</td>
<td>1.1405</td>
<td>7.7934</td>
<td>-2</td>
</tr>
<tr>
<td>1505</td>
<td>2018-07-01</td>
<td>Essendon</td>
<td>North Melbourne</td>
<td>2.0993</td>
<td>1.9022</td>
<td>17</td>
</tr>
<tr>
<td>1506</td>
<td>2018-07-01</td>
<td>Fremantle</td>
<td>Brisbane</td>
<td>1.2914</td>
<td>4.3743</td>
<td>-55</td>
</tr>
<tr>
<td>1507</td>
<td>2018-07-05</td>
<td>Sydney</td>
<td>Geelong</td>
<td>1.7807</td>
<td>2.2675</td>
<td>-12</td>
</tr>
<tr>
<td>1514</td>
<td>2018-07-08</td>
<td>Essendon</td>
<td>Collingwood</td>
<td>2.5442</td>
<td>1.6473</td>
<td>-16</td>
</tr>
<tr>
<td>1515</td>
<td>2018-07-08</td>
<td>West Coast</td>
<td>GWS</td>
<td>1.6790</td>
<td>2.4754</td>
<td>11</td>
</tr>
<tr>
<td>1516</td>
<td>2018-07-12</td>
<td>Adelaide</td>
<td>Geelong</td>
<td>2.0517</td>
<td>1.9444</td>
<td>15</td>
</tr>
<tr>
<td>1518</td>
<td>2018-07-14</td>
<td>Hawthorn</td>
<td>Brisbane</td>
<td>1.2281</td>
<td>5.4105</td>
<td>-33</td>
</tr>
<tr>
<td>1521</td>
<td>2018-07-14</td>
<td>GWS</td>
<td>Richmond</td>
<td>2.7257</td>
<td>1.5765</td>
<td>2</td>
</tr>
<tr>
<td>1522</td>
<td>2018-07-15</td>
<td>Collingwood</td>
<td>West Coast</td>
<td>1.5600</td>
<td>2.7815</td>
<td>-35</td>
</tr>
<tr>
<td>1523</td>
<td>2018-07-15</td>
<td>North Melbourne</td>
<td>Sydney</td>
<td>1.9263</td>
<td>2.0647</td>
<td>-6</td>
</tr>
<tr>
<td>1524</td>
<td>2018-07-15</td>
<td>Fremantle</td>
<td>Port Adelaide</td>
<td>5.9110</td>
<td>1.2047</td>
<td>9</td>
</tr>
<tr>
<td>1527</td>
<td>2018-07-21</td>
<td>Sydney</td>
<td>Gold Coast</td>
<td>1.0342</td>
<td>27.8520</td>
<td>-24</td>
</tr>
<tr>
<td>1529</td>
<td>2018-07-21</td>
<td>Brisbane</td>
<td>Adelaide</td>
<td>2.4614</td>
<td>1.6730</td>
<td>-5</td>
</tr>
<tr>
<td>1533</td>
<td>2018-07-22</td>
<td>Port Adelaide</td>
<td>GWS</td>
<td>1.6480</td>
<td>2.5452</td>
<td>-22</td>
</tr>
<tr>
<td>1538</td>
<td>2018-07-28</td>
<td>Gold Coast</td>
<td>Carlton</td>
<td>1.3933</td>
<td>3.5296</td>
<td>-35</td>
</tr>
<tr>
<td>1546</td>
<td>2018-08-04</td>
<td>Adelaide</td>
<td>Port Adelaide</td>
<td>2.0950</td>
<td>1.9135</td>
<td>3</td>
</tr>
<tr>
<td>1548</td>
<td>2018-08-04</td>
<td>St Kilda</td>
<td>Western Bulldogs</td>
<td>1.6120</td>
<td>2.6368</td>
<td>-35</td>
</tr>
<tr>
<td>1555</td>
<td>2018-08-11</td>
<td>Port Adelaide</td>
<td>West Coast</td>
<td>1.4187</td>
<td>3.3505</td>
<td>-4</td>
</tr>
<tr>
<td>1558</td>
<td>2018-08-12</td>
<td>North Melbourne</td>
<td>Western Bulldogs</td>
<td>1.3175</td>
<td>4.1239</td>
<td>-7</td>
</tr>
<tr>
<td>1559</td>
<td>2018-08-12</td>
<td>Melbourne</td>
<td>Sydney</td>
<td>1.3627</td>
<td>3.7445</td>
<td>-9</td>
</tr>
<tr>
<td>1564</td>
<td>2018-08-18</td>
<td>GWS</td>
<td>Sydney</td>
<td>1.8478</td>
<td>2.1672</td>
<td>-20</td>
</tr>
<tr>
<td>1576</td>
<td>2018-08-26</td>
<td>Brisbane</td>
<td>West Coast</td>
<td>2.3068</td>
<td>1.7548</td>
<td>-26</td>
</tr>
<tr>
<td>1578</td>
<td>2018-08-26</td>
<td>St Kilda</td>
<td>North Melbourne</td>
<td>3.5178</td>
<td>1.3936</td>
<td>-23</td>
</tr>
</tbody>
</table>
<p>Very interesting! Most of the games we got wrong were upsets. Let's have a look at the games we incorrectly predicted that weren't upsets.</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>(afl_data_one_line<span style="color: #666666">.</span>loc[afl_data_one_line<span style="color: #666666">.</span>game<span style="color: #666666">.</span>isin(game_ids), [<span style="color: #BA2121">&#39;date&#39;</span>, <span style="color: #BA2121">&#39;home_team&#39;</span>, <span style="color: #BA2121">&#39;opponent&#39;</span>, <span style="color: #BA2121">&#39;f_odds&#39;</span>, <span style="color: #BA2121">&#39;f_odds_away&#39;</span>, <span style="color: #BA2121">&#39;f_margin&#39;</span>]]
    <span style="color: #666666">.</span>assign(home_favourite<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">lambda</span> df: df<span style="color: #666666">.</span>apply(<span style="color: #008000; font-weight: bold">lambda</span> row: <span style="color: #666666">1</span> <span style="color: #008000; font-weight: bold">if</span> row<span style="color: #666666">.</span>f_odds <span style="color: #666666">&lt;</span> row<span style="color: #666666">.</span>f_odds_away <span style="color: #008000; font-weight: bold">else</span> <span style="color: #666666">0</span>, axis<span style="color: #666666">=1</span>))
    <span style="color: #666666">.</span>assign(upset<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">lambda</span> df: df<span style="color: #666666">.</span>apply(<span style="color: #008000; font-weight: bold">lambda</span> row: <span style="color: #666666">1</span> <span style="color: #008000; font-weight: bold">if</span> row<span style="color: #666666">.</span>home_favourite <span style="color: #666666">==</span> <span style="color: #666666">1</span> <span style="color: #AA22FF; font-weight: bold">and</span> row<span style="color: #666666">.</span>f_margin <span style="color: #666666">&lt;</span> <span style="color: #666666">0</span> <span style="color: #008000; font-weight: bold">else</span> 
                                      (<span style="color: #666666">1</span> <span style="color: #008000; font-weight: bold">if</span> row<span style="color: #666666">.</span>home_favourite <span style="color: #666666">==</span> <span style="color: #666666">0</span> <span style="color: #AA22FF; font-weight: bold">and</span> row<span style="color: #666666">.</span>f_margin <span style="color: #666666">&gt;</span> <span style="color: #666666">0</span> <span style="color: #008000; font-weight: bold">else</span> <span style="color: #666666">0</span>), axis<span style="color: #666666">=1</span>))
    <span style="color: #666666">.</span>query(<span style="color: #BA2121">&#39;upset == 0&#39;</span>))
</pre></div>

<table>
<thead>
<tr>
<th></th>
<th>date</th>
<th>home_team</th>
<th>opponent</th>
<th>f_odds</th>
<th>f_odds_away</th>
<th>f_margin</th>
<th>home_favourite</th>
<th>upset</th>
</tr>
</thead>
<tbody>
<tr>
<td>1412</td>
<td>2018-04-14</td>
<td>North Melbourne</td>
<td>Carlton</td>
<td>1.5799</td>
<td>2.7228</td>
<td>86</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>1425</td>
<td>2018-04-25</td>
<td>Collingwood</td>
<td>Essendon</td>
<td>1.8372</td>
<td>2.1754</td>
<td>49</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>1434</td>
<td>2018-04-29</td>
<td>Fremantle</td>
<td>West Coast</td>
<td>2.4926</td>
<td>1.6531</td>
<td>-8</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1437</td>
<td>2018-05-05</td>
<td>Essendon</td>
<td>Hawthorn</td>
<td>2.8430</td>
<td>1.5393</td>
<td>-23</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1452</td>
<td>2018-05-13</td>
<td>Collingwood</td>
<td>Geelong</td>
<td>2.4127</td>
<td>1.7040</td>
<td>-21</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1455</td>
<td>2018-05-19</td>
<td>North Melbourne</td>
<td>GWS</td>
<td>1.5049</td>
<td>2.9752</td>
<td>43</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>1461</td>
<td>2018-05-20</td>
<td>West Coast</td>
<td>Richmond</td>
<td>1.9755</td>
<td>2.0154</td>
<td>47</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>1467</td>
<td>2018-05-27</td>
<td>Hawthorn</td>
<td>West Coast</td>
<td>2.2123</td>
<td>1.8133</td>
<td>-15</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1479</td>
<td>2018-06-08</td>
<td>Port Adelaide</td>
<td>Richmond</td>
<td>1.7422</td>
<td>2.3420</td>
<td>14</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>1483</td>
<td>2018-06-10</td>
<td>Brisbane</td>
<td>Essendon</td>
<td>2.3018</td>
<td>1.7543</td>
<td>-22</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1493</td>
<td>2018-06-22</td>
<td>Port Adelaide</td>
<td>Melbourne</td>
<td>1.7391</td>
<td>2.3426</td>
<td>10</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>1501</td>
<td>2018-06-30</td>
<td>Adelaide</td>
<td>West Coast</td>
<td>1.4989</td>
<td>2.9756</td>
<td>10</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>1514</td>
<td>2018-07-08</td>
<td>Essendon</td>
<td>Collingwood</td>
<td>2.5442</td>
<td>1.6473</td>
<td>-16</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1515</td>
<td>2018-07-08</td>
<td>West Coast</td>
<td>GWS</td>
<td>1.6790</td>
<td>2.4754</td>
<td>11</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>1529</td>
<td>2018-07-21</td>
<td>Brisbane</td>
<td>Adelaide</td>
<td>2.4614</td>
<td>1.6730</td>
<td>-5</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1576</td>
<td>2018-08-26</td>
<td>Brisbane</td>
<td>West Coast</td>
<td>2.3068</td>
<td>1.7548</td>
<td>-26</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1578</td>
<td>2018-08-26</td>
<td>St Kilda</td>
<td>North Melbourne</td>
<td>3.5178</td>
<td>1.3936</td>
<td>-23</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>Let's now look at our model's log loss for the 2018 season compared to the odds.</p>
<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>predictions_probs <span style="color: #666666">=</span> lr<span style="color: #666666">.</span>predict_proba(test_x)
</pre></div>

<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>metrics<span style="color: #666666">.</span>log_loss(test_y, predictions_probs)
    <span style="color: #666666">0.584824211055384</span>
</pre></div>

<div class="codehilite" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span>test_x_unscaled <span style="color: #666666">=</span> feature_df<span style="color: #666666">.</span>loc[feature_df<span style="color: #666666">.</span>season <span style="color: #666666">==</span> <span style="color: #666666">2018</span>, [<span style="color: #BA2121">&#39;game&#39;</span>] <span style="color: #666666">+</span> feature_columns]

metrics<span style="color: #666666">.</span>log_loss(test_y, test_x_unscaled[[<span style="color: #BA2121">&#39;f_current_odds_prob_away&#39;</span>, <span style="color: #BA2121">&#39;f_current_odds_prob&#39;</span>]])
    <span style="color: #666666">0.5545776633924343</span>
</pre></div>

<p>So whilst our model performs decently, it doesn't beat the odds in terms of log loss. That's okay, it's still a decent start. In future iterations we can implement other algorithms and create new features which may improve performance.</p>
<hr />
<h2 id="next-steps">Next Steps<a class="headerlink" href="#next-steps" title="Permanent link">&para;</a></h2>
<p>Now that we have a model up and running, the next steps are to implement the model on a week to week basis. In the <a href="/modelling/AFLmodelPart4">next tutorial</a> we will be predicting the 2018 round of footy.</p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../AFLmodelPart2/" title="AFL 02. Feature creation" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                AFL 02. Feature creation
              </span>
            </div>
          </a>
        
        
          <a href="../AFLmodelPart4/" title="AFL 04. Weekly predictions" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                AFL 04. Weekly predictions
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
      </div>
      
        
  <div class="md-footer-social">
    <link rel="stylesheet" href="../../assets/fonts/font-awesome.css">
    
      <a href="https://twitter.com/Betfair_Aus" class="md-footer-social__link fa fa-twitter"></a>
    
      <a href="https://linkedin.com/company/betfair-australia" class="md-footer-social__link fa fa-linkedin"></a>
    
      <a href="https://facebook.com/betfareaustralia" class="md-footer-social__link fa fa-facebook"></a>
    
      <a href="https://youtube.com/user/betfairaus" class="md-footer-social__link fa fa-youtube"></a>
    
      <a href="https://github.com/betfair-datascientists" class="md-footer-social__link fa fa-github"></a>
    
  </div>

      
    </div>
    <div class="bf-footer">
      <p class="bf-light">Betfair Pty Limited is licensed and regulated by the Northern Territory Government of Australia.</p>
      <p class="bf-dark">Betfair Pty Limited's gambling operations are governed by its Responsible Gambling Code of Conduct and for South
      Australian residents by the South Australian Responsible Gambling Code of Practice.<br>Think! About your choices. Dont let the game play you. Stay in control. Gamble Responsibly.
      Call Gambling Help 1800 858 858 <a href="https://gamblinghelponline.org.au">www.gamblinghelponline.org.au</a></p>
      <ul class="bf-links">
        <li><a href="https://www.betfair.com.au/hub/help/account-help/responsible-gambling/">Responsible Gambling</a><span>|</span></li>
        <li><a href="http://www.betfair.com/AUS_NZL/aboutUs/Terms.and.Conditions/">Terms & Conditions</a><span>|</span></li>
        <li><a href="https://www.betfair.com.au/info/privacy-policy/">Privacy Policy</a><span>|</span></li>
        <li><a href="http://www.betfair.com/en/aboutUs/Rules.and.Regulations/">Rules & Regulations</a><span>|</span></li>
        <li><a href="https://www.betfair.com/AUS_NZL/aboutUs/Dispute.Resolution">Dispute Resolution</a></li>
      </ul>
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/application.83382bb6.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:"../.."}})</script>
      
        <script src="../../search/main.js"></script>
      
    
    
      
        <script>!function(e,a,t,n,o,c,i){e.GoogleAnalyticsObject=o,e.ga=e.ga||function(){(e.ga.q=e.ga.q||[]).push(arguments)},e.ga.l=1*new Date,c=a.createElement(t),i=a.getElementsByTagName(t)[0],c.async=1,c.src="https://www.google-analytics.com/analytics.js",i.parentNode.insertBefore(c,i)}(window,document,"script",0,"ga"),ga("create","UA-125973915-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview");var links=document.getElementsByTagName("a");if(Array.prototype.map.call(links,function(e){e.host!=document.location.host&&e.addEventListener("click",function(){var a=e.getAttribute("data-md-action")||"follow";ga("send","event","outbound",a,e.href)})}),document.forms.search){var query=document.forms.search.query;query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}</script>
      
    
  </body>
</html>